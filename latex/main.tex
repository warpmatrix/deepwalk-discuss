\documentclass{ctexart}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsfonts}
\geometry{bottom=2cm} 
\ctexset { section = { format={\Large \bfseries } } }
\bibliographystyle{unsrt}

\begin{document}
\input{content/cover.tex}

\tableofcontents
\newpage

\section{引言}

\subsection{图嵌入的背景和意义}

众所周知，图是一种基础且常用的数据结构，它使用点和边的集合描述不同实体之间的关系。图广泛地存在于各种现实应用中，可以描述复杂的现实场景，如社交网络、交通网络、通信网络等，甚至生物中的蛋白质相互作用、一个句子都可以使用图结构进行描述。通过对图的分析，我们可以深入了解社会结构、语言和不同的交流模式，因此图一直是学界研究的热点。

使用图结构可以解决很多实际中的问题，如：社交网络中的关系预测、通信网络中异常节点的预测和识别、蛋白质功能的模拟等等。将这些任务做进一步的抽象，图分析任务可以大致分为以下四类：（a）节点分类，（b）链路预测，（c）聚类，以及（d）可视化\cite{goyal2018graph}。其中，节点分类旨在基于其他标记的节点和网络拓扑来确定节点的标签；链路预测是指预测缺失链路或未来可能出现的链路；聚类用于将相似节点聚合在一起；可视化有助于深入了解网络结构。

图由边和节点表示，如果直接使用这些关系表示图的信息，一般只能使用数学或统计的方式进行数据处理。如果将图转换到向量空间表示，则有更加丰富的方法可以对图进行处理。对于一般的应用，图使用 \(|V| \times |V|\) 的邻接矩阵表示，但这样的方法对于现实生活中的大型图结构进行表征几乎是不可能的。一方面使用邻接矩阵表示图的信息，空间复杂度超过企业可以接受的范围；另外一方面，这样的编码方式并不能很好地反映图节点的信息。因此，使用图嵌入技术将图中的节点以低维稠密向量的形式进行表示，实际上将图的信息进行了压缩，打包在一个维度更小的向量中。这要求图嵌入的技术对节点映射为一个低维向量时，尽可能地保留节点的拓扑信息，在原图中接近的节点在低维特征空间也同样比较接近。

\subsection{问题描述}

对于图 $G=(V,E)$，节点集合 $V=\{v_1,\dots,v_n\}$，边集合 $E=\{ e_{ij} \}_{i,j=1}^n$。图嵌入是图节点的映射，映射 $f$ 在将节点映射到低维特征向量的同时，尝试保留节点之间的拓扑信息。

$$
f:v_i \to y_i \in \mathbb{R}^d, \;\forall i \in[0,n],\;where\; d \ll |V|
$$

节点之间的拓扑信息有多种方法可以衡量，其中一种常用的方法为使用节点之间的距离表示节点之间的拓扑信息。即在原图中两个节点之间有邻接关系或者两个节点距离较近，在映射后在低维向量空间中对应两个向量的距离同样比较接近，在这里衡量两个向量距离的接近程度通常使用两个向量的内积。因此，当前节点对应的拓扑信息，可以使用其邻居节点进行表示。

对于这一问题，DeepWalk 是其中一个最经典的方法，这个方法的思路和上述使用邻居节点表示节点的拓扑信息有异曲同工的地方。DeepWalk 使用的随机游走策略将在当前节点的邻居中等概率地选择下一个要访问节点，这实际上仅利用了节点之间的连接信息来提取节点序列，在一定程度上保留了节点的拓扑信息。虽然 DeepWalk 是 KDD 2014 的工作，但它为我们实现图嵌入提供了很好的思路，是我们了解图嵌入无法绕过的一个方法。

\subsection{本文工作}

本文主要讨论了图嵌入问题并深入了解 DeepWalk 算法的思路和实现，并且对 DeepWalk 进行一系列的讨论，尝试对不同类型的图改进 DeepWalk 中节点序列的提取的策略，根据节点以及连接之间更多的信息来指导节点的选择：

\begin{itemize}
    \item 根据采样节点与起始节点的距离，调整返回上一节点的概率。
    \item 根据采样节点的邻居的度数，调整选择该邻居作为下一节点的概率。
\end{itemize}

% TODO: 完成全篇再进行更新
本文的其余部分安排如下。在第二节中，我们将介绍图嵌入算法的发展。在第三节中，我们将讲述Deepwalk算法原理和改进。在第四节中，我们将展示和分析实验结果。在第五节中，我们将做出总结并给出未来的改进方向。

\section{DeepWalk 方法的简单介绍}

\subsection{对图嵌入问题的进一步讨论}

图嵌入的核心目标在于将图上的节点映射到一个低维向量上，这一向量可以保留节点的拓扑信息。这个问题本质上是将一个高维稀疏的向量映射到一个低维稠密的向量上，并且能够保留相应的信息量。并且值得一提的是，这样的映射成立有其对应的原因，对于现实中的稀疏图，使用邻接矩阵存储网络的信息可能存在大量的信息冗余。一个节点的信息体主要体现在和它的邻居节点，以社交网络为例，其中存在两个常见的现象：

\begin{itemize}
    \item 社交平台上存在一些大 V，他们的影响力较大，和大量的节点存在邻接关系。
    \item 社交平台上存在不同的圈子：圈子内部的用户可能相互关联互相关注，甚至可能上述提到的大 V 就可能是圈子中的一个代表元；圈子之间的用户可能关联较少，甚至可能存在相互独立的子图。
\end{itemize}

上述提到的两个现象，尤其是圈子现象说明了使用邻接矩阵表示节点之间的关系可能存在大量的数据冗余。特别是两个相互独立的圈子（在一些关联较弱的圈子内部也可以近似看作两个相互独立的圈子）之间的用户代表两个相互独立的子图，在邻接矩阵中占据了冗余的信息空间。因此，使用节点的邻居节点的信息可以极大程度上表示节点的拓扑信息，在社交网络中可以对应为用户的圈子信息。

而且在上述的社交网络模型中，使用向量的内积作为衡量两个向量相似的指标，可以很好地解释上面的两个现象。通常而言，两个向量的夹角较小可以看作两个用户在同一个圈子内部；而向量的模比较大可以看作用户的影响力比较大，在其方向上和多个向量的内积都比较大，容易和多个用户产生关联。

综合上述两点，根据节点的邻接信息构建向量，进而描述图的相关信息有其的合理性；并且使用向量的内积作为衡量两个向量的相似程度，也十分具有解释性。

\subsection{DeepWalk 方法的介绍}

DeepWalk 使用了类似的思想使用节点的邻居信息表示节点的拓扑信息。通过随机游走的方式对邻居节点进行采样获得对应的节点的拓扑信息。DeepWalk 创造性地将词嵌入方法 word2vec 引入到图嵌入中，结合上述的邻居节点信息得到节点和节点的共现关系，再用 word2vec 模型将节点的邻接信息看作词句，再学习使用将上述的邻居信息编码为向量形式。

% TODO: 随机游走成立的原因（分布

% TODO: 使用 word2vec 和 NLP 的相似之处，幂律分布？

\section{基于 DeepWalk 算法的进一步讨论}

在上面的讨论中可以得知，DeepWalk 使用随机游走的方式对邻居节点进行采样，实现的效果为距离当前节点较近的邻居节点被采样的概率比较大，距离当前节点比较远的邻居节点被采样的概率比较小。根据这一特性，我们可以针对不同类型的图作出进一步的讨论，依据不同类型的图结构，选择合适的采样方法使得 DeepWalk 的准确率尽可能提升。

\subsection{基于度数对 DeepWalk 的讨论}

\subsection{基于路径对 DeepWalk 的讨论}

\section{实验结果与分析}

\section{相关工作陈述}

图嵌入算法是一种将图中节点、边及其特征转换为较低维度的向量空间，同时最大限度地保留图结构和信息等属性的方法。约二十年前，人们提出了图嵌入算法，算法思想是根据实际问题构造一个D维空间中的图，然后将图的节点嵌入到d（d<<D）维向量空间中，嵌入指的是在向量空间中保持邻接的节点彼此靠近。在过去的十年里，在图嵌入领域已经有了大量的研究，重点是设计新的嵌入算法。发展到现在，大体上可以将这些嵌入方法分为三大类：（1）基于因子分解的方法，（2）基于随机游走的方法，以及（3）基于深度学习的方法\cite{goyal2018graph}。

\subsection{基于因子分解的方法}

\begin{itemize}
    \item Locally Linear Embedding，局部线性嵌入，局部线性假设每个节点都是相邻节点的线性组合。通过最小化目标函数$\phi(Y)=\sum_{i=1}^N|y_i-\sum_{j=1}^kw_{ij}y_j|^2$得到嵌入矩阵$Y$。
    \item Laplacian Eigenmaps，拉普拉斯特征映射，在权重$w_{ij}$较高时，如果在嵌入后被分割过远，则给予更高的惩罚。通过最小化目标函数$\phi(Y)=\frac{1}{2}\sum_{ij} |y_i-y_j|^2w_{ij}$进行求解。
\end{itemize}

\subsection{基于随机游走的方法}

\begin{itemize}
    \item DeepWalk受到word2vec的启发，选择某一特定点作为起始点，通过随机游走得到一系列点的序列，用word2vec来学习该序列，从而得到表示该点的向量。
    \item node2vec和DeepWalk类似，但在随机游走这一步骤中使用有偏随机游走，即通过参数控制，使得随机游走反映出类似于DFS或BFS的采样特性，从而提高采样的效果。
\end{itemize}

\subsection{基于深度学习的方法}
\begin{itemize}
    \item SDNE使用深度自动编码器来保持一阶和二阶网络临近度，该方法通过自动编码器来寻找一个重构邻域节点的嵌入，并基于拉普拉斯特征映射来对嵌入结果进行评判反馈。
    \item DNGR使用随机游走模型来生成概率共现矩阵，将该矩阵转化为PPMI矩阵，输入到叠加去噪自动编码器中得到嵌入结果。
\end{itemize}

\section{总结与展望}

\bibliography{reference}
\end{document}

% \begin{figure}
%     \centering]
%     \includegraphics[width=8cm]{image/exec-overview.png}
%     \caption{MapReduce: Execution overview}
%     \label{fig: exec-overview}
% \end{figure}
