\documentclass{ctexart}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsfonts}
\geometry{bottom=2cm} 
\ctexset { section = { format={\Large \bfseries } } }
\bibliographystyle{unsrt}

\begin{document}
\input{content/cover.tex}

\tableofcontents
\newpage

\section{引言}

\subsection{研究基于 DeepWalk 图嵌入算法的背景和意义}

众所周知，图是一种基础且常用的数据结构，广泛地存在于各种现实应用中，如社交网络、交通网络和通信网络。通过对它们的分析，我们可以深入了解社会结构、语言和不同的交流模式，因此图一直是学界研究的热点。

图分析任务可以大致分为以下四类：（a）节点分类，（b）链路预测，（c）聚类，以及（d）可视化\cite{goyal2018graph}。其中，节点分类旨在基于其他标记的节点和网络拓扑来确定节点的标签。链路预测是指预测缺失链路或未来可能出现的链路。聚类用于将相似节点聚合在一起。可视化有助于深入了解网络结构。

图嵌入技术将图中的节点以低维稠密向量的形式进行表示，要求在原始图中相似的节点其在低维特征空间也接近。

虽然 DeepWalk 是 KDD 2014 的工作，但却是我们了解图嵌入无法绕过的一个方法。DeepWalk 创造性地将词嵌入方法 word2vec 引入到图嵌入中，通过随机游走的策略提取节点序列，得到节点和节点的共现关系，再用 word2vec 模型学习节点的向量表示。

\subsection{问题描述}

对于图$G=(V,E)$，节点集合$V=\{v_1,\dots,v_n\}$，边集合$ E=\{ e_{ij} \}_{i,j=1}^n $。图嵌入是图节点的映射，映射$f$在将节点映射到低维特征向量的同时，尝试保留节点之间的拓扑信息。

$$
f:v_i \to y_i \in \mathbb{R}^d, \;\forall i \in[0,n],\;where\; d \ll |V|
$$

DeepWalk 使用的随机游走策略将在当前节点的邻居中等概率地选择下一个要访问节点，这实际上仅利用了节点之间的连接信息来提取节点序列，在拓扑信息的保留上还不够全面。

\subsection{本文工作}

我们尝试改进了 DeepWalk中节点序列的提取，根据节点以及连接之间更多的信息来指导节点的选择：

\begin{itemize}
    \item 根据采样节点与起始节点的距离，调整返回上一节点的概率。
    \item 根据采样节点的邻居的度数，调整选择该邻居作为下一节点的概率。
\end{itemize}

\subsection{论文结构简介}

本文的其余部分安排如下。在第二节中，我们将介绍图嵌入算法的发展。在第三节中，我们将讲述Deepwalk算法原理和改进。在第四节中，我们将展示和分析实验结果。在第五节中，我们将做出总结并给出未来的改进方向。

\section{相关工作陈述}

图嵌入算法是一种将图中节点、边及其特征转换为较低维度的向量空间，同时最大限度地保留图结构和信息等属性的方法。约二十年前，人们提出了图嵌入算法，算法思想是根据实际问题构造一个D维空间中的图，然后将图的节点嵌入到d（d<<D）维向量空间中，嵌入指的是在向量空间中保持邻接的节点彼此靠近。在过去的十年里，在图嵌入领域已经有了大量的研究，重点是设计新的嵌入算法。发展到现在，大体上可以将这些嵌入方法分为三大类：（1）基于因子分解的方法，（2）基于随机游走的方法，以及（3）基于深度学习的方法\cite{goyal2018graph}。

\subsection{基于因子分解的方法}

\begin{itemize}
    \item Locally Linear Embedding，局部线性嵌入，局部线性假设每个节点都是相邻节点的线性组合。通过最小化目标函数$\phi(Y)=\sum_{i=1}^N|y_i-\sum_{j=1}^kw_{ij}y_j|^2$得到嵌入矩阵$Y$。
    \item Laplacian Eigenmaps，拉普拉斯特征映射，在权重$w_{ij}$较高时，如果在嵌入后被分割过远，则给予更高的惩罚。通过最小化目标函数$\phi(Y)=\frac{1}{2}\sum_{ij} |y_i-y_j|^2w_{ij}$进行求解。
\end{itemize}

\subsection{基于随机游走的方法}

\begin{itemize}
    \item DeepWalk受到word2vec的启发，选择某一特定点作为起始点，通过随机游走得到一系列点的序列，用word2vec来学习该序列，从而得到表示该点的向量。
    \item node2vec和DeepWalk类似，但在随机游走这一步骤中使用有偏随机游走，即通过参数控制，使得随机游走反映出类似于DFS或BFS的采样特性，从而提高采样的效果。
\end{itemize}

\subsection{基于深度学习的方法}
\begin{itemize}
    \item SDNE使用深度自动编码器来保持一阶和二阶网络临近度，该方法通过自动编码器来寻找一个重构邻域节点的嵌入，并基于拉普拉斯特征映射来对嵌入结果进行评判反馈。
    \item DNGR使用随机游走模型来生成概率共现矩阵，将该矩阵转化为PPMI矩阵，输入到叠加去噪自动编码器中得到嵌入结果。
\end{itemize}

\section{基于 DeepWalk 图嵌入算法的改进}

\subsection{DeepWalk图嵌入算法}

\subsection{采样策略的改进}

\section{实验结果与分析}

\section{总结与展望}



\bibliography{reference}
\end{document}

% \begin{figure}
%     \centering]
%     \includegraphics[width=8cm]{image/exec-overview.png}
%     \caption{MapReduce: Execution overview}
%     \label{fig: exec-overview}
% \end{figure}

% \begin{itemize}
%     \item RDD 和其他日志一样，只能进行读操作，不能被直接修改。只能通过 transform 操作创建新的 RDD 对象。
%     \item RDD 基于内存进行操作，可以全部或部分存储在内存当中，并且 RDD 可以在多次计算中反复重用，实现利用内存实现低延时的计算。
%     \item 同时，当内存不足时，RDD 和正常使用的计算机数据一样具有弹性的特点，计算的过程中可以和磁盘进行数据交换保证节点有足够大小的内存进行计算。
%     \item RDD 可以具有分布式的特点。它可以保存在集群中的不同节点，从而进行并行计算。
% \end{itemize}
