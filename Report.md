# 基于 DeepWalk 图嵌入算法改进



## 摘要





【关键词】：



## 引言

### 研究基于 DeepWalk 图嵌入算法的背景和意义

众所周知，图是一种基础且常用的数据结构，广泛地存在于各种现实应用中，如社交网络、交通网络和通信网络。通过对它们的分析，我们可以深入了解社会结构、语言和不同的交流模式，因此图一直是学界研究的热点。

图分析任务可以大致分为以下四类：（a）节点分类，（b）链路预测，（c）聚类，以及（d）可视化。其中，节点分类旨在基于其他标记的节点和网络拓扑来确定节点的标签。链路预测是指预测缺失链路或未来可能出现的链路。聚类用于将相似节点聚合在一起。可视化有助于深入了解网络结构。

图嵌入技术将图中的节点以低维稠密向量的形式进行表示，要求在原始图中相似的节点其在低维特征空间也接近。

虽然 DeepWalk 是 KDD 2014 的工作，但却是我们了解图嵌入无法绕过的一个方法。DeepWalk 创造性地将词嵌入方法 word2vec 引入到图嵌入中，通过随机游走的策略提取节点序列，得到节点和节点的共现关系，再用 word2vec 模型学习节点的向量表示。

### 问题描述

对于图 $G=(V,E)$ ，节点集合 $V=\{v_1,\dots,v_n\}$ ，边集合 $ E=\{ e_{ij} \}_{i,j=1}^n $ ，图嵌入是图节点的映射：

$$  f:v_i \to y_i \in \mathbb{R}^d, \;\forall i \in[0,n],\;where\; d \ll |V| $$

映射 $f$ 在将节点映射到低维特征向量的同时，尝试保留节点之间的拓扑信息。

DeepWalk 使用的随机游走策略将在当前节点的邻居中等概率地选择下一个要访问节点，这实际上仅利用了节点之间的连接信息来提取节点序列，在拓扑信息的保留上还不够全面。

### 本文工作

我们尝试改进了 DeepWalk 中节点序列的提取，根据节点以及连接之间更多的信息来指导节点的选择：

- 根据采样节点与起始节点的距离，调整返回上一节点的概率
- 根据采样节点的邻居的度数，调整选择该邻居作为下一节点的概率

### 论文结构简介

本文的其余部分安排如下。在第二节中，我们将介绍图嵌入算法的发展和Deep Walk 图嵌入算法的原理。在第三节中，我们将讲述对于 DeepWalk 的改进。在第四节中，我们将展示和分析实验结果。第第五节中，我们将做出总结并给出未来的改进方向。



## 相关工作陈述

### 图嵌入算法的发展

图嵌入算法是一种将图中节点、边及其特征转换为较低维度的向量空间，同时最大限度地保留图结构和信息等属性的方法。

约20年前，图形嵌入算法被提出，算法思想是根据实际问题构造一个D维空间中的图，然后将图的节点嵌入到d（d<<D）维向量空间中，在向量空间中保持连接的节点彼此靠近。许多经典的基于因子分解的算法（LLE等）均源自该思想。可扩展性是这种方法的一个主要问题，因为算法的时空复杂度往往较高。

自2010年以来，相关的算法研究转移到可伸缩图嵌入技术上，如LINE、DeepWalk等；并出现与深度学习进行融合的算法，如结合自动编码器的SDNE等。在下文中将简要介绍图嵌入算法的几种类别及其代表性的算法。

我们可以将嵌入大致分为三类：

( 1 )基于因子分解的方法

1. LLE

Locally Linear Embedding，局部线性嵌入，假设每个节点都是嵌入空间中相邻节点的线性组合。如果假设图G的邻接矩阵元素代表节点j能够表示节点i的权重，则对于图中每个节点i定义
$$
Y_i\approx \sum_i W_{ij}Y_j
$$
通过最小化
$$
\phi(Y)=\sum_i |Y_i-\sum_jW_{ij}Y_j|^2
$$
来求解。LLE对数据的流形分布特征有严格的要求，比如不能是稀疏的数据集，不能是分布不均匀的数据集等等，这限制了它的应用。

2. Laplacian Eigenmaps

拉普拉斯特征映射，在权重$W_{ij}$较高时，如果在嵌入后被分割过远，则给予更高的反馈（惩罚）。通过最小化目标函数进行求解：

$$
\phi(Y)=\frac{1}{2}\sum_{ij} |Y_i-Y_j|^2W_{ij}
$$

( 2 )基于随机游走的方法

1. DeepWalk

该方法受到word2vec的启发，选择某一特定点作为起始点，通过随机游走得到一系列点的序列，用word2vec来学习该序列，从而得到表示该点的向量；

2. node2vec

该方法类似DeepWalk，但在随机游走这一步骤中使用有偏随机游走，即通过参数控制，使得随机游走反映出类似于DFS或BFS的采样特性，从而提高采样的效果；

( 3 )基于深度学习的方法

1. SDNE

使用深度自动编码器来保持一阶和二阶网络临近度，该方法通过自动编码器来寻找一个重构邻域节点的嵌入，并基于拉普拉斯特征映射来对嵌入结果进行评判反馈。

2. DNGR

使用随机游走模型来生成概率共现矩阵，将该矩阵转化为PPMI矩阵，输入到叠加去噪自动编码器中得到嵌入结果。

（4）其它

LINE

LINE为每对顶点定义了两个联合概率分布，一个使用邻接矩阵，另一个使用嵌入。然后，LINE最小化了这两个分布的Kullback–Leibler（KL）散度。

$$
p_1(v_i,v_j)=\frac{1}{1+exp(-<Y_i,Y_j>)} \\
\hat{p}_1(v_i,v_j)=\frac{W_{ij}}{\sum_{(i,j)\in E}W_{ij}} \\
O_1=KL(\hat{p_1},p_1)
$$



### DeepWalk 图嵌入算法

random walk

从某个特定端点开始，在网络中不断重复地随机选择游走路径，最终形成贯穿网络的节点序列。

random walk是广泛采用的获取网络局部结构特征的方法[38]，且在算法性能上具有优势，局部的游走在全局的网络中并不会相互影响，使得并行计算多个随机游走成为可能，且随机游走关心局部结构的特性使得网络的局部变化只会影响局部范围内的随机游走结果，不需要重新计算全部特定端点的随机游走；

deep walk采用截断随机游走(truncated random walk)，即长度固定的随机游走，在实际实验中，随机游走的截断长度是重要的参数，长的随机游走在采样分布上会包含更大的范围，为模型训练提供更多的“单词上下文”，但加大计算复杂度，同时使网络局部的变化可以影响更多的随机游走结果；

word2vec

用于词嵌入（word embedding），目的是让训练后的模型可以将每个单词映射到向量上，从而表示单词之间的关系；该方法基于词袋模型（Bag-of-words model)，在该模型下，根据句子或文档的词出现频率进行训练，而不考虑文法和单词顺序。

在实验中，如果一个连通图的度分布满足幂次法则，那节点在短的随机游走中出现的频率也会遵循幂律分布特征；基于这一特性，可认为网络中随机游走的分布规律与NLP中句子序列在语料库中出现的规律有着类似的幂律分布特征；在理论上，word2vec不考虑文法与词序的特性也更符合网络节点以邻近性为特征采样而得到的结果；故Deep Walk将word2vec的方法应用于网络节点间，类比word2vec处理单词序列的方式来处理随机游走得到的节点序列，并认为具有相似邻域的节点会有相近的嵌入结果。

通过结合random walk与word2vec，Deep Walk算法最终成为了在性能和适应性上优秀的算法，被广泛运用于图嵌入领域，但截断随机游走算法的参数调整只为长度，不能很好地利用节点的其余信息（如节点的度），这也是本文主要的研究方向。


## 基于 DeepWalk 图嵌入算法的改进




## 实验结果与分析







## 总结与展望





## 参考文献





## 致谢















